# de-project-sprint-10
 final project

# наполнение staging
	Поскольку в Vertica есть команда COPY ... FROM LOCAL ... было решено выбрать источником S3 bucket 
	и сохранять файлы локально. в папке \data создается директория, имя которой - вчерашняя дата (2023-02-27).
	В нее выкладываются файлы истории курсов валют и 10 батчей с транзакциями. Все это делает DAG S3_to_local.py
	Затем спустя 10 минут (в 00-15 следующего дня) из этой папки происходит наполнения staging слоя в Vertica
	"один к одному", т.е. структура таблиц полностью повторяется. Создание структуры - init_stg.sql. Результат 
	загрузки можно видеть на скриншотах currencies.png и transactions.png. Также в таблице transactions_max_date
	сохраняются все даты загрузки.
	
# наполнение cdm слоя
	Цитата из задания:
	"Сделайте так, чтобы витрина обновлялась ежедневно инкрементом на основании данных из таблиц transactions и currencies. 
	Каждый день должна добавляться новая запись за вчера."
	Поэтому предполагается что витрина будет наполняться из stg слоя. Данных для нормельного DWH нет, но тем не менее я создал
	заготовку таблиц для dwh-слоя чтобы впоследствии можно было бы обогатить stg-слой и из него наполнить dwh-слой (init_dwh.sql)
	По моему dwh должен быть таким как на DWH.phg
	Тем не менее создаем (init_cdm.sql) и заполняем витрины (DAG - stg_to_cdm.py). Инкрементальность загрузки обеспечивается фильтром
	из таблицы transactions_max_date stage-слоя (выбираем оттуда последнюю дату загрузки в предложении  WHERE)
	Итоги видно на скрине global_metrics.png
	
# Ссылка на схему и таблицу в Vertica, где расположена итоговая витрина - GRIGORJEVDEYANDEXRU.global_metrics
# Скриншот визуализации дашборда - metabase_visualisation.png
